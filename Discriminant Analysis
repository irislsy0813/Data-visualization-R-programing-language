library(MASS)
library(ggplot2)
library(tidyverse)
library(viridis)

n<-nrow(mpg)
train_or_test<-ifelse(runif(n)<0.7,'Train','Test')  ##把所有数据分成train和test，runif min = 0, max = 1随机数。
table(train_or_test)  ##table可以查看不同变量总数

mpg_exp<-add_column(mpg,Sample=train_or_test)
view(mpg_exp)

mpg_train<-filter(mpg_exp,Sample=='Train')
mpg_test<-filter(mpg_exp,Sample=='Test')

summary(mpg_train)
summary(mpg_test)  ##两者的mean很接近即为好

##lda（trainningy~trainningx, data=trainning data）

lda_out<-lda(drv~displ+hwy,data = mpg_train)##找规律

ldapred<-predict(lda_out,mpg_test)##对实验数据mpg_test做预测

##Missclasification Rate

mean(ldapred$class!=mpg_test$drv) ##错误概率

table(ldapred$class,mpg_test$drv)

### qda

qda_out<-qda(drv~displ+hwy,data = mpg_train) ##找规律

qdapred<-predict(qda_out,mpg_test) ##对实验数据mpg_test做预测

##Missclasification Rate

mean(qdapred$class!=mpg_test$drv)

table(qdapred$class,mpg_test$drv)

table(qdapred$class,ldapred$class) ##row, col


### Evaluate whether the assumptions of multivariate normality and homogenous variances and covariances hold.

mpg_train%>%
  group_by(drv)%>%
  summarise(VarDispl=var(displ),
            VarHwy=var(hwy),
            covDisplHwy=cov(displ,hwy))->varcov 
## `summarise()` ungrouping output (override with `.groups` argument)

mpg_train%>%
  ggplot(aes(x=displ,y=hwy,col=drv))+
  geom_density2d()+
  scale_color_colorblind()

######################练习##############
#Use MASS package
library(MASS)
#Later tidyverse also used
library(tidyverse)

#Load in data
ExistingWines<-readRDS('ExistingWines.rds').     -----train data

##Carry out Linear Discriminant Analysis (LDA) using all data in ExistingWines.rds in the training set and predict the data in NewWines.rds.
#Load in New Wine Data

NewWines<-readRDS('NewWines.rds')              -----test data
ldaout<-lda(BestMarket~.,data = ExistingWines)
ldaout

##newdata = NewWines = test datda
yhat_lda<-predict(ldaout,newdata = NewWines)

##What are the predictions for the first ten wines in the NewWines.rds
head(yhat_lda$class,10)

head(yhat_lda$posterior,10)

##Repeat the analyis using Quadratic Disciminant Analysis (QDA).     -------QDA

qdaout<-qda(BestMarket~.,data = ExistingWines)
yhat_qda<-predict(qdaout,newdata = NewWines)
head(yhat_qda$class,10)

##Split the data in ExistingWines.rds into a training sample (of roughly 70%) and a test sample (of roughly 30%).-----自己分数据
#Create an indicator that determines whether it is training or test sample.

ind<-ifelse(runif(125)<0.7,"Training Sample","Test Sample")

#A data set augmented with sample information

Data_with_Sample<-add_column(ExistingWines,Sample=ind)

#Get Training data
train_data<-Data_with_Sample%>%
  filter(Sample=="Training Sample")%>%
  select(-Sample)                                ##Can remove Sample variable

#Get Test data

test_data<-Data_with_Sample%>%
  filter(Sample=="Test Sample")%>%
  select(-Sample)                                 #Can remove Sample variable

## Is LDA better than QDA for this data?

ldaout<-lda(BestMarket~.,data = train_data)
yhat_lda<-predict(ldaout,newdata = test_data)
mean(yhat_lda$class!=test_data$BestMarket)

qdaout<-qda(BestMarket~.,data = train_data)
yhat_qda<-predict(qdaout,newdata = test_data)
mean(yhat_qda$class!=test_data$BestMarket)

## Under what assumptions would QDA theoretically be better than LDA. Investigate whether this assumption holds
## QDA is better if the variance covariance matrices are different for different groups 检查variance大不大

ExistingWines%>%
  group_by(BestMarket)%>%
  summarise_all(var)->Variances
Variances

##What other assumption is required for LDA or QDA to theoretically minimise misclassification rate? Think of a way to do a quick visual check of whether this assumption holds.
#Both LDA and QDA are only optimal under normality 检查是否是normal distribution.

ExistingWines%>%
  gather(key = Variable, value = Value,-BestMarket)%>%
  ggplot(aes(x=Value,col=BestMarket))+geom_density()+facet_wrap(~Variable,nrow = 4,scales = 'free')
  
####
Double Cross Validation（2-fold Cross Validation，记为2-CV）
做法是将数据集分成两个相等大小的子集，进行两回合的分类器训练。在第一回合中，一个子集作为training set，另一个便作为testing set；
在第二回合中，则将training set与testing set对换后，再次训练分类器，而其中我们比较关心的是两次testing sets的辨识率。
不过在实务上2-CV并不常用，主要原因是training set样本数太少，通常不足以代表母体样本的分布，导致testing阶段辨识率容易出现明显落差。
此外，2-CV中分子集的变异度大，往往无法达到“实 验过程必须可以被复制”的要求。
